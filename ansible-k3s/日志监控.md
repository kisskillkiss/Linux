一,简介  
>在网上查了下k8s日志收集,有三种方法分别是:  
1,伴生容器作为日志代理:每个pod安装个Fluentd,缺点编排文件配置稍微复杂  
2,日志存到pv里,缺点日志不统一,但是做nfs日志写入延迟很大,分布式文件服务器目前项目用不到,浪费资源  
3,Node级日志代理,没用日志太多,pod运行日志都写进去,做筛选比较废资源  
因为我们现在项目pod不多,地三种没用日志比较多,而第二种日志多了不做分布式文件服务器的话读取写入延迟很大,所以最后采用第三种方案  
  
二,部署es  
1,Elasticsearch运行时要求vm.max_map_count内核参数必须大于262144.  
sysctl -w vm.max_map_count=262144  
2,给节点打标签  
kubectl get node  
NAME     STATUS   ROLES    AGE   VERSION  
master   Ready    master   25h   v1.14.3-k3s.1  
node-1   Ready    worker   25h   v1.14.3-k3s.1  
node-2   Ready    worker   25h   v1.14.3-k3s.1  
kubectl label nodes node-2 labelName=node-2  
3,部署单节点es服务器  
kubectl apply -f es.yaml --namespace=ek(可选,指定命名空间)  
es编排文件详解  
```  
kind: List  
apiVersion: v1  
items:  
- apiVersion: apps/v1beta1  
  kind: Deployment  
  metadata:  
    name: es  
  spec:  
    replicas: 1   #单节点  
    template:  
      metadata:  
        name: es  
        labels:  
          app: es  
      spec:  
        containers:  
        - image: docker.elastic.co/elasticsearch/elasticsearch:6.8.2  
          name: es  
          resources:  
            limits:  
              cpu: 2  
              memory: 2048Mi  
            requests:  
              cpu: 300m  
              memory: 1024Mi  
          env:  
          - name: network.host  
            value: "_site_"  
          - name: node.name  
            value: "${HOSTNAME}"  
          - name: discovery.zen.ping.unicast.hosts  
            value: "${ES_SVC_SERVICE_HOST}"  
          - name: cluster.name  
            value: "JXD"     #集群名字  
          - name: ES_JAVA_OPTS  
            value: "-Xms128m -Xmx128m"  
          volumeMounts:  
          - name: es-data  
            mountPath: /usr/share/elasticsearch/data/nodes  
        volumes:  
        - name: es-data  
          persistentVolumeClaim:  
            claimName: es-data-pvc  
        nodeSelector:  
          labelName: node-2  
- apiVersion: v1  
  kind: PersistentVolume  
  metadata:  
    name: es-pv  
    labels:  
      ek: es          #要保证与pvc标签一样,pv与pvc通过标签关联的  
  spec:  
    capacity:  
      storage: 30Gi  
    volumeMode: Filesystem  
    lasessModes:  
    - ReadWriteMany  #多个节点读写权限,ReadOnlyMany多个节点只读权限,ReadWriteOnce单个节点读写权限  
    nfs:  
      path: /opt/data/elasticsearch    #这里说下,可能有人疑问前面说方案2nfs延迟比较大,这里传过来的日志都是经过filebeat筛选的,而直接挂在pv是所有日志,所以这里的nfs负载没那么大
      server: 172.17.57.241      #nfs服务器,node-2节点要挂载  
- apiVersion: v1  
  kind: PersistentVolumeClaim  
  metadata:  
    name: es-data-pvc  
    labels:  
      ek: es  
  spec:  
    lasessModes:  
      - ReadWriteMany  
    resources:  
      requests:  
        storage: 30Gi  
- apiVersion: v1  
  kind: Service  
  metadata:   
    name: es-svc  
  spec:  
    type: NodePort  
    ports:  
    - name: http  
      port: 9200  
      targetPort: 9200  
      nodePort: 31200  
    - name: tcp  
      port: 9300  
      targetPort: 9300  
      nodePort: 31300  
    selector:  
      app: es  
```  
查看  
```  
kubectl get pv,pvc,svc,deployment -n ek  
NAME                               CAPACITY   lasESS MODES   RECLAIM POLICY   STATUS   CLAIM                  STORAGECLASS   REASON   AGE  
persistentvolume/es-pv             30Gi       RWX            Retain           Bound    ek/es-data-pvc                                 4s  
  
NAME                                STATUS   VOLUME   CAPACITY   lasESS MODES   STORAGECLASS   AGE  
persistentvolumeclaim/es-data-pvc   Bound    es-pv    30Gi       RWX                           4s  
  
NAME             TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)                         AGE  
service/es-svc   NodePort   10.43.213.85   <none>        9200:31200/TCP,9300:31300/TCP   4s  
  
NAME                       READY   UP-TO-DATE   AVAILABLE   AGE  
deployment.extensions/es   1/1     1            1           4s  
```  
测试是否正常:  
```  
curl 127.0.0.1:31200  
{  
  "name" : "es-74cfcb6785-255fg",  
  "cluster_name" : "JXD",  
  "cluster_uuid" : "pm82epXSSkKYYGha5uFCWg",  
  "version" : {  
    "number" : "6.8.2",  
    "build_flavor" : "default",  
    "build_type" : "docker",  
    "build_hash" : "b506955",  
    "build_date" : "2019-07-24T15:24:41.545295Z",  
    "build_snapshot" : false,  
    "lucene_version" : "7.7.0",  
    "minimum_wire_compatibility_version" : "5.6.0",  
    "minimum_index_compatibility_version" : "5.0.0"  
  },  
  "tagline" : "You Know, for Search"  
}  
```  
三,部署kibana  
kubectl apply -f eb.yaml --namespace=ek  
```  
apiVersion: apps/v1  
kind: Deployment  
metadata:  
  name: kb  
  labels:  
    app: kb  
spec:  
  replicas: 1  
  selector:  
    matchLabels:  
      app: kb  
  template:  
    metadata:  
      labels:  
        app: kb  
    spec:  
      containers:  
      - name: kb  
        image: docker.elastic.co/kibana/kibana:6.8.2  
        resources:  
          limits:  
            cpu: 1000m  
            memory: 1024Mi  
          requests:  
            cpu: 100m  
        env:  
          - name: ELASTICSEARCH_URL  
            value: http://es-svc:9200  
        ports:  
        - containerPort: 5601  
          name: ui  
          protocol: TCP  
---  
kind: Service  
apiVersion: v1  
metadata:  
  name: kb-svc  
spec:  
  selector:  
    app: kb  
  ports:  
    - protocol: TCP  
      port: 5601  
      nodePort: 32601  
      name: ui  
  type: NodePort  
```  
查看  
```  
kubectl get pv,pvc,svc,deployment -n ek |grep kb  
service/kb-svc   NodePort   10.43.164.237   <none>        5601:32601/TCP                  60s  
deployment.extensions/kb   1/1     1            1           60s  
```  
使用浏览器访问,能打开就没问题了,正常来说需要验证,但是我们只有一个办公地点,我直接限制只有我们公网ip才能访问,所以这里不讲登录验证了  
四,pod伴生filebeat  
kubectl apply -f las.yaml --namespace=jxd  
tomcat项目编排文件  
```  
kind: List  
apiVersion: v1  
items:  
- apiVersion: v1  
  kind: ConfigMap  
  metadata:  
    name: las-filebeat-config  
    labels:  
      app: las  
  data:  
    filebeat.yml: |  
      processors:  
        - add_cloud_metadata:  
      filebeat.modules:  
      - module: system  
      filebeat.inputs:  
      - type: log  
        paths:  
          - /logs/*.log  #日志目录  
        symlinks: true  
      output.elasticsearch:  
        hosts: ['172.17.57.241:31200']   #es地址,这里可以用ingress转换成域名,以后我会写这个  
      output.elasticsearch.index: "las-%{+yyyy.MM.dd}"   #索引格式  
      setup.template.name: "las"  
      setup.template.pattern: "las-*"  
      logging.level: info   
---  
apiVersion: extensions/v1beta1  
kind: Deployment  
metadata:  
  name: las  
spec:  
  template:  
    metadata:  
      labels:  
        app: las  
    spec:  
      containers:  
      - name: las  
        image: las:1  
        imagePullPolicy: Never  
        resources:  
          requests:  
            cpu: 0.5  
            memory: 200Mi  
          limits:  
            cpu: 1  
            memory: 800Mi  
        volumeMounts:  
        - name: tomcat-log  
          mountPath: /tomcat/logs/       #程序日志目录  
      - name: filebeat  
        image: docker.elastic.co/beats/filebeat:6.8.2  
        imagePullPolicy: Never  
        args: [  
          "-c", "/home/filebeat-config/filebeat.yml",  
          "-e",  
        ]  
        securityContext:  
          runAsUser: 0  
        volumeMounts:  
        - name: tomcat-log  
          mountPath: /logs/              #伴生容器挂载程序目录日志目录配置,要与ConfigMap配置一样  
        - name: "filebeat-volume"  
          mountPath: "/home/filebeat-config"  
      volumes:  
        - name: tomcat-log  
          emptyDir: {}  
        - name: filebeat-volume  
          configMap:  
            name: las-filebeat-config      #ConfigMap名字,一定要对  
```  
2,测试  
查看详细信息  
```  
kubectl get svc,deployment,configMap -njxd  
NAME                      TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)           AGE  
service/las-svc           NodePort   10.43.212.168   <none>        8080:30899/TCP    25h  
NAME                        READY   UP-TO-DATE   AVAILABLE   AGE  
deployment.extensions/las   1/1     1            1           2m33s  
NAME                                    DATA   AGE  
configmap/las-filebeat-config           1      25h  
```  
看看es上有没有数据  
```  
curl 127.0.0.1:31200/las-*  
{"las-2019.08.28":{"aliases":{},"mappings":{"doc":{"_meta":{"version":"6.8.2"},"dynamic_templates":[{"fields":{"path_match":"fields.*","match_mapping_type":"string","mapping":{"type":"keyword"}}},{"docker.container.labels":{"path_match":"docker.container.labels.*","match_mapping_type":"string","mapping":{"type":"keyword"}}}……  
```  
